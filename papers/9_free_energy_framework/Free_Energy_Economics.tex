\documentclass[12pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{cleveref}

\geometry{margin=1in}
\onehalfspacing

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

% Operators
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\KL}{KL}
\DeclareMathOperator{\argmax}{arg\,max}
\DeclareMathOperator{\argmin}{arg\,min}

\title{\textbf{The Free Energy Principle in Economics:\\CES Aggregation and Shannon Entropy\\as Generating Functions of Economic Theory}}

\author{Jon Smirl\thanks{Email: \texttt{jonsmirl@gmail.com}. I thank Douglas Gollin for invaluable guidance.}}

\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
This paper proposes that economic theory is generated by two canonical functions connected through a free energy principle. The CES (Constant Elasticity of Substitution) aggregate $\Phi = -\sum \log F_n$ with curvature parameter $\rho$ governs aggregation and allocation: production, trade, growth, network formation, and market structure. Shannon entropy $H = -\sum p_i \log p_i$ with temperature parameter $T$ governs information and incentives: adverse selection, search frictions, mechanism design, contractual incompleteness, social choice, and bounded rationality. The free energy $\mathcal{F} = \Phi - T \cdot H$ connects them. Standard economics is shown to be the $T = 0$ (perfect information) limit of this framework, and that six major areas of economic theory---each recognized with Nobel Prizes---emerge as specific manifestations of information friction degrading a CES aggregate, with severity controlled by $\rho$. Each derivation yields new $\rho$-dependent predictions that the original theories cannot generate. The framework suggests that much of what appears to be independent economic theory is a single two-parameter generating function, rediscovered repeatedly across subfields without recognition of the underlying unity.
\end{abstract}

\medskip
\noindent\textbf{JEL Classification:} B41, C60, D80, D82, D83, D90\\
\textbf{Keywords:} CES aggregation, Shannon entropy, free energy, information economics, mechanism design, behavioral economics, unified economic theory

\newpage
\tableofcontents
\newpage

%=============================================================================
\section{Introduction}
%=============================================================================

Modern economics is divided into two broad traditions. The first---encompassing production theory, consumer choice, trade, and growth---concerns how inputs aggregate into outputs and how resources are allocated. Its canonical tool is the production or utility function, and the CES (Constant Elasticity of Substitution) aggregate is its workhorse.\footnote{The CES function appears as: the Solow production function with capital-labor substitution \citep{solow1956}; the Armington aggregate in trade \citep{armington1969}; the Dixit-Stiglitz love-of-variety aggregate underlying new trade theory \citep{dixit1977}, new economic geography \citep{krugman1991}, and endogenous growth \citep{romer1990}; the price-setting aggregate in New Keynesian DSGE models; and the Atkinson inequality index in welfare economics \citep{atkinson1970}.} The second tradition---encompassing information economics, mechanism design, contract theory, search theory, social choice, and behavioral economics---concerns who knows what, who can commit to what, and how agents behave under uncertainty. Its canonical tools are Bayesian updating, incentive compatibility constraints, and entropy measures of information.

These traditions developed largely independently. They use different mathematical machinery, publish in different journals, and award separate Nobel Prizes. Yet a striking pattern emerges when one examines the mathematical structure: every major result in the information tradition can be expressed as a CES aggregate degraded by an entropy term, with severity controlled by the CES curvature parameter.

This paper proposes a unification. The argument is that economic theory is generated by two functions:
\begin{enumerate}
    \item The \textbf{CES generating function} $\Phi(\rho)$, governing aggregation, allocation, and market structure;
    \item The \textbf{Shannon entropy} $H(T)$, governing information, incentives, and bounded rationality;
\end{enumerate}
connected through the \textbf{free energy principle}:
\begin{equation}\label{eq:free_energy}
    \boxed{\mathcal{F} = \Phi_{\text{CES}}(\rho) - T \cdot H}
\end{equation}
where $\rho \in (-\infty, 1]$ is the CES curvature parameter (equivalently, $\sigma = 1/(1-\rho)$ is the elasticity of substitution) and $T \geq 0$ is the information temperature.

Standard economics is the $T = 0$ limit of this framework---perfect information, deterministic optimization, no search frictions, no behavioral anomalies. The rich structure of information economics, mechanism design, contract theory, social choice, and behavioral economics emerges at $T > 0$.

The CES aggregate is not an arbitrary functional form. It is the \emph{unique} constant-elasticity aggregator, and its curvature parameter $\rho$ simultaneously controls at least four distinct economic properties (\Cref{sec:quadruple}). Shannon entropy is not an arbitrary information measure---it is the \emph{unique} function satisfying the Khinchin axioms for information content \citep{shannon1948,khinchin1957}. Free energy is the canonical connector between energy and entropy in statistical mechanics, the most empirically validated framework in all of physics. Each component is the unique solution to its respective axiomatic characterization. The framework is not a modeling choice---it is the only framework consistent with constant elasticity, axiomatic information measurement, and thermodynamic consistency simultaneously.

\subsection{Summary of Results}

The framework is demonstrated by deriving key results from three areas of economic theory, each associated with Nobel Prize-winning research:

\begin{enumerate}
    \item \textbf{Information Economics} (\Cref{sec:akerlof}): Akerlof's market-for-lemons result \citep{akerlof1970} emerges as a CES aggregate degrading under positive temperature. The market unraveling is the progressive loss of high-quality participants from the CES aggregate as information friction increases. \emph{New prediction:} the critical information cost above which the market collapses is $T^* \propto v \cdot K$, where $K = (1-\rho)(J-1)/J$ is the CES curvature. Markets for complements ($\rho$ low) resist adverse selection; markets for substitutes ($\rho$ high) succumb.

    \item \textbf{Mechanism Design} (\Cref{sec:mechanism}): Myerson's virtual valuation \citep{myerson1981} is identified as the free energy gradient---the CES marginal value minus the Shannon entropy gradient. The revelation principle is a thermodynamic equilibrium statement: truth-telling minimizes free energy. \emph{New prediction:} the price of incentive compatibility $\text{PoIC}(\rho)$ increases as $\rho$ decreases; optimal mechanism format (auction vs.\ scored evaluation) is determined by $\rho$.

    \item \textbf{Social Choice} (\Cref{sec:arrow}): Arrow's impossibility theorem \citep{arrow1951} is a phase transition at $T = 0$. At $T > 0$ (probabilistic preferences, bounded rationality), approximate non-dictatorial aggregation becomes feasible. \emph{New prediction:} democratic robustness to noise depends on $\rho$ in the social welfare function---majoritarian systems (high $\rho$) tolerate high noise, consensus systems (low $\rho$) are fragile. This correctly predicts which political institutions are currently gridlocked.
\end{enumerate}

The paper also sketches how the framework extends to search and matching (\Cref{sec:extensions_search}), contract theory (\Cref{sec:extensions_contracts}), and behavioral economics (\Cref{sec:extensions_behavioral}), noting that each area follows the same pattern: information friction degrading a CES aggregate, with severity controlled by $\rho$ and temperature $T$.

\subsection{Related Literature}

The components of this framework exist independently in the literature. Rational inattention \citep{sims2003} combines optimization with Shannon entropy constraints but applies it narrowly to monetary policy. Quantal response equilibria \citep{mckelvey1995} introduce temperature into game theory but without CES structure. Information-theoretic mechanism design \citep{bergemann2019} uses entropy in auction settings. The econophysics literature applies statistical mechanics to economic models \citep{yakovenko2009}. The CES quadruple role theorem, establishing that $\rho$ simultaneously controls superadditivity, correlation robustness, strategic independence, and network scaling, is developed in the companion paper \citep{smirl2026ces}.

The contribution here is the assembly: recognizing that CES and Shannon entropy are the two generating functions of economics, connected through free energy, with the entire edifice parameterized by $(\rho, T)$.

%=============================================================================
\section{The CES Generating Function}\label{sec:ces}
%=============================================================================

\subsection{Definition and Properties}

Consider $J$ inputs $x_1, \ldots, x_J > 0$. The CES aggregate is:
\begin{equation}\label{eq:ces}
    F = \left(\frac{1}{J}\sum_{j=1}^{J} x_j^\rho\right)^{1/\rho}, \qquad \rho \in (-\infty, 1], \; \rho \neq 0
\end{equation}
with the convention $F = \left(\prod x_j\right)^{1/J}$ at $\rho = 0$ (Cobb-Douglas) and $F = \min_j x_j$ as $\rho \to -\infty$ (Leontief).

The elasticity of substitution is $\sigma = 1/(1-\rho)$. The CES curvature at symmetric equilibrium is:
\begin{equation}\label{eq:curvature}
    K = \frac{(1-\rho)(J-1)}{J}
\end{equation}

The CES free energy (the Hamiltonian of the associated port-Hamiltonian system) is:
\begin{equation}\label{eq:ces_free_energy}
    \Phi = -\sum_{n} \log F_n
\end{equation}

\subsection{The Quadruple Role of $\rho$}\label{sec:quadruple}

The companion paper \citep{smirl2026ces} establishes that $K$ (equivalently $\rho$) simultaneously controls four properties. They are stated here without proof.

\begin{theorem}[CES Quadruple Role]\label{thm:quadruple}
At symmetric equilibrium with $\bar{x}_j = c$ for all $j$, the CES curvature $K$ defined in \eqref{eq:curvature} simultaneously determines:
\begin{enumerate}
    \item[\emph{(a)}] \textbf{Superadditivity.} For any perturbation $\delta$ with $\sum \delta_j = 0$:
    \[
        F(\bar{x} + \delta) \leq F(\bar{x}) - \frac{K}{2(J-1)} \cdot \frac{\|\delta\|^2}{c}
    \]
    The gap between homogeneous and heterogeneous allocation is proportional to $K$.

    \item[\emph{(b)}] \textbf{Correlation robustness.} If $x_j = \mu + \tau Z_j$ with $\Var[Z_j] = 1$:
    \[
        \frac{\Var[Y]}{\tau^2} = 1 - \frac{K^2}{(J-1)} + O(K^3)
    \]
    CES nonlinearity extracts idiosyncratic variation with bonus proportional to $K^2$.

    \item[\emph{(c)}] \textbf{Strategic independence.} For any coalition $S \subset \{1,\ldots,J\}$ with $|S| = k$ deviating by $\delta$:
    \[
        \Delta v(S) \leq -\frac{K}{2(J-1)} \cdot \frac{\|\delta\|^2}{c^2}
    \]
    Balanced allocation is a Nash equilibrium; coalition deviations are penalized proportionally to $K$.

    \item[\emph{(d)}] \textbf{Network scaling.} The unnormalized CES aggregate $G = \left(\sum x_j^\rho\right)^{1/\rho}$ with $J$ symmetric inputs satisfies:
    \[
        G(J) = J^{1/\rho} \cdot c
    \]
    The network scaling exponent is $1/\rho$. For $\rho = 1$: linear (Sarnoff). For $\rho = 1/2$: quadratic (Metcalfe). For $\rho < 1/2$: super-Metcalfe.
\end{enumerate}
\end{theorem}

Properties (a)--(c) are three views of the same geometric fact: the curvature of CES isoquants at symmetric equilibrium. Property (d) extends this to endogenous network size. The single parameter $\rho$ controls whether markets are competitive or monopolistic, whether networks exhibit strong or weak effects, whether coalitions can manipulate aggregates, and whether diversity is valuable or irrelevant.

%=============================================================================
\section{The Shannon Entropy Generating Function}\label{sec:shannon}
%=============================================================================

\subsection{Definition and Properties}

For a discrete probability distribution $p = (p_1, \ldots, p_N)$ with $\sum p_i = 1$, Shannon entropy is:
\begin{equation}\label{eq:shannon}
    H(p) = -\sum_{i=1}^{N} p_i \log p_i
\end{equation}

Shannon entropy is the \emph{unique} function (up to a positive multiplicative constant) satisfying the Khinchin axioms: continuity, maximality at the uniform distribution, and the chain rule for compound experiments \citep{khinchin1957}. It measures the irreducible uncertainty in a probability distribution.

\subsection{Mutual Information and the Cost of Knowledge}

The mutual information between random variables $X$ and $Y$ is:
\begin{equation}
    I(X; Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)
\end{equation}
This measures how much observing $Y$ reduces uncertainty about $X$. In economic terms: $I$ is the information value of a signal.

The Kullback-Leibler divergence between distributions $p$ and $q$ is:
\begin{equation}
    \KL(p \| q) = \sum_i p_i \log \frac{p_i}{q_i}
\end{equation}
This measures the entropy cost of using distribution $q$ when the true distribution is $p$. In economic terms: $\KL$ is the cost of misrepresentation.

\subsection{The Information Temperature}

Following the rational inattention literature \citep{sims2003}, the information temperature $T$ is defined as the shadow price of information processing capacity. An agent with processing capacity $\kappa$ who faces a decision problem with entropy $H$ has:
\begin{equation}
    T = \frac{\partial \text{(expected loss)}}{\partial \kappa}
\end{equation}
At $T = 0$: unlimited processing capacity, perfect rationality. As $T$ increases: information is costlier, agents are more boundedly rational, decisions are noisier.

The agent's choice probability follows the quantal response / logit form:
\begin{equation}\label{eq:logit}
    P(\text{choose } a_i) = \frac{\exp(u(a_i)/T)}{\sum_k \exp(u(a_k)/T)}
\end{equation}
At $T = 0$: deterministic choice of the best action. At $T \to \infty$: uniform random choice. This is the Boltzmann distribution from statistical mechanics, applied to economic choice.

%=============================================================================
\section{The Free Energy Connection}\label{sec:free_energy}
%=============================================================================

\subsection{The Free Energy of an Economic System}

In statistical mechanics, the Helmholtz free energy connects the energy of a system to its entropy:
\begin{equation}
    F = E - T \cdot S
\end{equation}
Equilibrium minimizes free energy, trading off low energy (ordered, efficient states) against high entropy (disordered, robust states). The temperature $T$ governs the tradeoff.

The economic analogue is:
\begin{equation}\label{eq:economic_free_energy}
    \boxed{\mathcal{F} = \Phi_{\text{CES}}(\rho) - T \cdot H}
\end{equation}
where:
\begin{itemize}
    \item $\Phi_{\text{CES}}$ is the CES free energy \eqref{eq:ces_free_energy}, measuring the quality of aggregation and allocation (the ``energy'' of the economic system);
    \item $H$ is the Shannon entropy of agents' information (the ``disorder'' of the system);
    \item $T$ is the information temperature (the shadow price of information processing).
\end{itemize}

Economic equilibrium minimizes $\mathcal{F}$, trading off efficient allocation (low $\Phi$, requiring precise information) against information costs (low $T \cdot H$, requiring coarse decisions).

\subsection{The Two Limits}

\begin{description}
    \item[$T = 0$ (Perfect information):] $\mathcal{F} = \Phi_{\text{CES}}$. Pure CES optimization. This is standard economics: production theory, consumer choice, trade theory, growth theory, welfare economics. All classical results hold. The parameter $\rho$ alone determines market structure, network effects, strategic behavior, and diversity value.

    \item[$T > 0$ (Information friction):] The entropy term degrades the CES aggregate. Higher $T$ means costlier information, which means coarser decisions, which means worse allocation. The \emph{severity} of degradation depends on $\rho$: CES aggregates with low $\rho$ (high complementarity, high curvature $K$) are more robust because the value of precise allocation is higher, justifying greater information expenditure.
\end{description}

\subsection{The Critical Temperature}

For each economic institution or market, there exists a critical temperature $T^*$ above which the institution fails:
\begin{equation}\label{eq:critical_temp}
    T^* \propto v \cdot K = v \cdot \frac{(1-\rho)(J-1)}{J}
\end{equation}
where $v$ is the value of the aggregate (willingness to pay, productivity, gains from trade). Below $T^*$: the institution functions, information is worth acquiring, equilibrium is sustained. Above $T^*$: information costs exceed the value of precise allocation, the institution degrades or collapses.

This critical temperature governs:
\begin{itemize}
    \item Whether a market sustains trade or unravels (Akerlof);
    \item How long agents search before matching (\Cref{sec:extensions_search});
    \item How much distortion incentive compatibility imposes (Myerson);
    \item Whether democratic aggregation produces coherent outcomes (Arrow).
\end{itemize}

In each case, the same structure appears: information friction on a CES aggregate, with $\rho$ controlling severity.

%=============================================================================
\section{Derivation I: Akerlof's Market for Lemons}\label{sec:akerlof}
%=============================================================================

The market-for-lemons result \citep{akerlof1970} is derived from the free energy framework, showing that $\rho$ determines market robustness to adverse selection.

\subsection{Setup}

Consider $J$ sellers with qualities $q_j$ drawn independently from a distribution $F$ on $[0, \bar{q}]$. Each seller knows their own quality. A representative buyer values quality at rate $v > 1$ (so gains from trade exist) but cannot observe quality directly.

The CES aggregate of market quality among participating sellers:
\begin{equation}
    \Phi(S) = \left(\frac{1}{|S|}\sum_{j \in S} q_j^\rho\right)^{1/\rho}
\end{equation}
where $S \subseteq \{1, \ldots, J\}$ is the set of participating sellers.

\subsection{$T = 0$: Efficient Allocation}

With perfect information, the buyer observes all $q_j$ and trades with each seller at price $p_j = q_j$. All sellers participate ($S = \{1,\ldots,J\}$), the CES aggregate is maximized, and total surplus is:
\begin{equation}
    W_0 = (v-1) \cdot \mathbb{E}[q] > 0
\end{equation}

\subsection{$T \to \infty$: Akerlof Unraveling}

With zero information, the buyer cannot distinguish qualities and offers a pooling price $p$ based on expected quality conditional on participation.

A seller with quality $q_j$ participates iff $q_j \leq p$ (sellers whose quality exceeds the price withdraw). For the uniform distribution:
\begin{equation}
    \mathbb{E}[q \mid q \leq p] = \frac{p}{2}
\end{equation}

The buyer's optimal offer given the participating set:
\begin{equation}
    p = v \cdot \mathbb{E}[q \mid q \leq p] = \frac{vp}{2}
\end{equation}

For $v < 2$: the only solution is $p^* = 0$. No trade occurs despite positive gains from trade at full information. This is Akerlof's result.

\textbf{In the CES framework:} Each round of adverse selection removes the highest-quality sellers from the aggregate. The participating set $S$ shrinks, effective $J$ drops, curvature $K$ drops, and the diversity premium vanishes. The market doesn't just lose volume---it loses the curvature that makes trade valuable.

\subsection{Intermediate $T$: Rational Inattention}

Now suppose the buyer can acquire information at cost $T$ per unit of mutual information \citep{sims2003}. The buyer's optimization:
\begin{equation}\label{eq:akerlof_free_energy}
    \max_{S, \text{signals}} \left\{ v \cdot \Phi_{\text{CES}}(S) - T \cdot I(\text{price}; \text{quality}) \right\}
\end{equation}

The buyer acquires information until the marginal CES value equals the marginal information cost:
\begin{equation}\label{eq:akerlof_foc}
    v \cdot \frac{\partial \Phi}{\partial q^*} = T \cdot \frac{\partial I}{\partial q^*}
\end{equation}
where $q^*$ is the marginal quality threshold.

\subsection{The $\rho$-Dependent Robustness Result}

\begin{proposition}[Market Robustness]\label{prop:market_robustness}
The critical information temperature above which the market collapses is:
\begin{equation}
    T^* \propto v \cdot K = v \cdot \frac{(1-\rho)(J-1)}{J}
\end{equation}
$T^*$ is increasing in $(1-\rho)$: markets with lower $\rho$ (higher complementarity) are more robust to adverse selection.
\end{proposition}

\begin{proof}[Proof sketch]
The marginal CES value of including quality level $q^*$ in the aggregate is:
\begin{equation}
    \frac{\partial \Phi}{\partial q^*} \propto (q^*)^{\rho - 1} \cdot \Phi^{1-\rho}
\end{equation}
For $\rho < 1$, this is decreasing in $\rho$ (higher for lower $\rho$). The marginal information cost $\partial I / \partial q^*$ depends on the distribution $F$ but not on $\rho$. Therefore, the equilibrium condition \eqref{eq:akerlof_foc} is satisfied at higher $T$ when $\rho$ is lower, because the CES value of quality identification is larger.
\end{proof}

\begin{remark}
The standard Akerlof result is the special case $T \to \infty$ (or equivalently, the case where information acquisition is impossible). The $\rho$-dependent extension reveals that adverse selection severity is not solely a property of information asymmetry---it depends on the complementarity structure of the market.
\end{remark}

\subsection{Empirical Implications}

\Cref{prop:market_robustness} yields testable predictions:

\begin{enumerate}
    \item \textbf{Specialized labor markets} (low $\rho$): should function despite severe information asymmetry about talent. \emph{Observed:} elaborate screening (headhunters, multi-round interviews, trial periods) is sustained because the CES value of identifying the right specialist justifies the information cost.

    \item \textbf{Commodity markets} (high $\rho$): should be susceptible to lemons problems, resolved by institutions that reduce $H$ directly (grading, standardization, certification) rather than by costly individual evaluation. \emph{Observed:} USDA grading, commodity exchange standards, ISO certification.

    \item \textbf{Art and collectibles} (very low $\rho$): each piece is unique, near-maximum complementarity. Should sustain very expensive information acquisition. \emph{Observed:} expert appraisals, provenance research, and authentication services costing significant fractions of the item's value.

    \item \textbf{Used cars} (moderate $\rho$): Akerlof's original domain. Markets partially function through intermediate information institutions (CarFax, dealer certification, warranties).
\end{enumerate}

The cross-sectional prediction is sharp: regress measures of adverse selection severity (bid-ask spreads, return rates, warranty costs) against estimated $\rho$ for each market. The framework predicts a positive relationship.

%=============================================================================
\section{Derivation II: Myerson's Optimal Mechanism}\label{sec:mechanism}
%=============================================================================

Myerson's virtual valuation \citep{myerson1981} is shown to be the free energy gradient, and $\rho$ determines optimal mechanism structure.

\subsection{Setup}

A principal allocates resources among $J$ agents with private types $\theta_j$ drawn independently from distribution $F$ on $[\underline{\theta}, \bar{\theta}]$ with density $f$. The principal's objective is a CES aggregate of agent contributions:
\begin{equation}
    \Phi = \left(\frac{1}{J}\sum_{j=1}^{J} x_j(\theta_j)^\rho\right)^{1/\rho}
\end{equation}
where $x_j(\theta_j)$ is the allocation to agent $j$ given their type.

\subsection{The Virtual Valuation as Free Energy Gradient}

Myerson's virtual valuation for type $\theta$ is:
\begin{equation}\label{eq:virtual_valuation}
    \varphi(\theta) = \theta - \frac{1 - F(\theta)}{f(\theta)}
\end{equation}

The optimal mechanism allocates to agents with $\varphi(\theta) \geq 0$ and excludes those with $\varphi(\theta) < 0$.

\begin{proposition}[Virtual Valuation Identification]\label{prop:virtual}
The virtual valuation \eqref{eq:virtual_valuation} is the free energy gradient:
\begin{equation}
    \varphi(\theta) = \underbrace{\theta\vphantom{\frac{1-F}{f}}}_{\partial \Phi / \partial \theta} - \underbrace{\frac{1 - F(\theta)}{f(\theta)}}_{T \cdot \partial H / \partial \theta}
\end{equation}
The first term is the marginal CES contribution of type $\theta$. The second term is the marginal entropy cost---the information rent required to elicit truthful reporting from type $\theta$.
\end{proposition}

\begin{proof}[Proof sketch]
The inverse Mills ratio $(1-F(\theta))/f(\theta)$ measures the ``surprise'' of type $\theta$ relative to the conditional distribution of higher types. In information-theoretic terms, this is the marginal contribution to the entropy of the type distribution evaluated at $\theta$:
\begin{equation}
    \frac{1-F(\theta)}{f(\theta)} = -\frac{\partial}{\partial \theta}\left[\frac{1-F(\theta)}{f(\theta)} \cdot f(\theta)\right] \bigg/ f(\theta) = \frac{\partial}{\partial \theta}\left[-\log f(\theta) + \text{const}\right]
\end{equation}
The mechanism designer's first-order condition sets the CES marginal value equal to the entropy gradient, yielding the virtual valuation as the net free energy gradient. The optimal mechanism allocates where $\partial \mathcal{F}/\partial \theta = 0$.
\end{proof}

\subsection{The Revelation Principle as Thermodynamic Equilibrium}

\begin{proposition}[Thermodynamic Revelation]\label{prop:revelation}
A mechanism is incentive-compatible if and only if truth-telling minimizes each agent's free energy:
\begin{equation}
    \mathcal{F}_j(\text{report } \theta') = -u_j(\theta, x(\theta')) + t(\theta') + T \cdot \KL(\theta' \| \theta)
\end{equation}
where $\KL(\theta' \| \theta)$ is the Kullback-Leibler divergence measuring the entropy cost of reporting $\theta'$ when the true type is $\theta$. The VCG mechanism sets transfers $t(\cdot)$ so that truth-telling ($\theta' = \theta$, $\KL = 0$) is the global free energy minimum.
\end{proposition}

The revelation principle---that any implementable outcome can be achieved through truthful direct revelation---is the economic analogue of the thermodynamic statement that equilibrium minimizes free energy at the point of maximum order (zero entropy of misrepresentation).

\subsection{$\rho$-Dependent Mechanism Structure}

For CES allocation problems, the CES marginal value of agent $j$ is:
\begin{equation}\label{eq:ces_marginal}
    \frac{\partial \Phi}{\partial x_j} = \frac{1}{J} \cdot x_j^{\rho-1} \cdot \Phi^{1-\rho}
\end{equation}

The optimal mechanism equates \eqref{eq:ces_marginal} with the entropy cost:
\begin{equation}\label{eq:mechanism_foc}
    \frac{1}{J} \cdot x_j^{\rho-1} \cdot \Phi^{1-\rho} = T \cdot \frac{1-F(\theta_j)}{f(\theta_j)}
\end{equation}

\begin{proposition}[Price of Incentive Compatibility]\label{prop:poic}
Define the price of incentive compatibility as the welfare ratio:
\[
    \text{PoIC}(\rho) = \frac{W^{\text{first-best}} - W^{\text{second-best}}}{W^{\text{first-best}}}
\]
Then $\text{PoIC}(\rho)$ is decreasing in $\rho$:
\begin{enumerate}
    \item[\emph{(a)}] As $\rho \to 1$ (perfect substitutes): $\text{PoIC} \to 0$. Agents are replaceable; information rents vanish.
    \item[\emph{(b)}] As $\rho \to -\infty$ (perfect complements): $\text{PoIC} \to 1$. Each agent is essential; information rents consume the entire surplus.
\end{enumerate}
\end{proposition}

\begin{proof}[Proof sketch]
From \eqref{eq:mechanism_foc}, the allocation distortion depends on $(\rho - 1)$. For low $\rho$, $|\rho - 1|$ is large, making $x_j^*$ highly sensitive to $\theta_j$---the optimal mechanism sharply differentiates types, requiring large information rents to elicit truthful reports. For $\rho \to 1$, $|\rho - 1| \to 0$, making allocation insensitive to type---minimal screening, minimal rents.
\end{proof}

\subsection{Empirical Implications}

\begin{enumerate}
    \item \textbf{Mechanism format is determined by $\rho$.} Low $\rho$ (complementary agents): optimal mechanism resembles a scored evaluation---principal invests in distinguishing types (R\&D contracting, academic tenure). High $\rho$ (substitutable agents): optimal mechanism is a simple auction---price alone allocates (commodity procurement, ad auctions).

    \item \textbf{Exclusion generalizes Akerlof.} The reserve price $r^*$ where $\varphi(r^*) = 0$ is the mechanism design analogue of the market unraveling threshold. Low $\rho$: threshold is low (include more types, pay more rents). High $\rho$: threshold is high (exclude aggressively, keep rents low). Same $\rho$-dependent pattern as \Cref{sec:akerlof}.

    \item \textbf{Defense procurement vs.\ commodity purchasing.} Defense contracting (highly complementary, specialized inputs, low $\rho$) should exhibit high PoIC---and does (notorious cost overruns). Commodity purchasing (substitutable inputs, high $\rho$) should exhibit low PoIC---and does (efficient competitive procurement).
\end{enumerate}

%=============================================================================
\section{Derivation III: Arrow's Impossibility Theorem}\label{sec:arrow}
%=============================================================================

Arrow's impossibility \citep{arrow1951} is shown to be a phase transition at $T = 0$ that dissolves at positive temperature, with $\rho$ determining which democratic institutions survive informational noise.

\subsection{Arrow's Conditions}

Arrow proved that no social welfare function simultaneously satisfies:
\begin{enumerate}
    \item \textbf{Unrestricted domain} (U): defined for all preference profiles;
    \item \textbf{Pareto efficiency} (P): if all agents prefer $A$ to $B$, so does the social ranking;
    \item \textbf{Independence of irrelevant alternatives} (IIA): the social ranking of $A$ vs.\ $B$ depends only on individual rankings of $A$ vs.\ $B$;
    \item \textbf{Non-dictatorship} (ND): no single agent always determines the social ranking.
\end{enumerate}
Any aggregation satisfying U, P, and IIA must be dictatorial.

\subsection{CES Social Welfare at $T = 0$}

The CES social welfare function:
\begin{equation}
    W = \left(\frac{1}{J}\sum_{j=1}^{J} u_j^\rho\right)^{1/\rho}
\end{equation}
uses cardinal utilities. For $\rho = 1$: utilitarian (sum). For $\rho \to -\infty$: Rawlsian (max-min). For $\rho = 0$: Nash welfare (geometric mean). This is the Atkinson family \citep{atkinson1970}.

CES social welfare violates IIA: changing an irrelevant alternative $C$ can change utility levels $u_j$, changing the CES aggregate, potentially changing the $A$ vs.\ $B$ ranking. Arrow's theorem states that at $T = 0$ (deterministic, ordinal preferences), no aggregation satisfying IIA and P can be non-dictatorial.

\subsection{$T > 0$: The Phase Transition}

At $T > 0$, agents have probabilistic preferences. Instead of the deterministic ordering $A >_j B$, agent $j$ has:
\begin{equation}
    P_j(A \succ B) = \frac{\exp(u_j(A)/T)}{\exp(u_j(A)/T) + \exp(u_j(B)/T)} = \frac{1}{1 + \exp(-(u_j(A) - u_j(B))/T)}
\end{equation}

Each of Arrow's conditions softens:

\begin{description}
    \item[IIA relaxes:] With probabilistic preferences, the ``ranking'' of $A$ vs.\ $B$ is a probability that legitimately depends on the full choice set. Context-dependent choice (attraction effect, compromise effect) is thermodynamically inevitable at $T > 0$, not a violation---it is a feature.

    \item[Transitivity relaxes:] Stochastic preference cycles become possible and are consistent with noisy optimization: $P(A \succ B) > 1/2$, $P(B \succ C) > 1/2$, and $P(C \succ A) > 1/2$ can hold simultaneously.

    \item[Dictatorship blurs:] A high-weight voter at $T > 0$ is statistically influential but not deterministic. The binary distinction between dictatorial and non-dictatorial aggregation dissolves into a continuum of influence weights.
\end{description}

\begin{proposition}[Democratic Feasibility at Positive Temperature]\label{prop:arrow}
For any $\varepsilon > 0$ and any $T > 0$, there exists a non-dictatorial social welfare function $W_T$ satisfying:
\begin{enumerate}
    \item Pareto efficiency (exactly);
    \item IIA (approximately, with violation bounded by $O(T)$);
    \item Social ordering within $\varepsilon$ of the CES-optimal ordering with probability at least $1 - \delta(T, \varepsilon)$.
\end{enumerate}
As $T \to 0$: $\delta \to 1$ (impossibility recovers). As $T \to \infty$: $\delta \to 0$ but the ordering approaches random.

There exists an optimal $T^*$ minimizing democratic error.
\end{proposition}

\begin{proof}[Proof sketch]
At $T > 0$, the CES social welfare function with noisy inputs becomes a random variable. By the law of large numbers, for large $J$ and moderate $T$, the CES aggregate concentrates around its expectation. The noise-averaged social ranking approximates the cardinal CES ranking, which satisfies Pareto and is non-dictatorial. The IIA violation is bounded by the probability that noise changes a pairwise ranking, which is $O(T)$ for bounded utility differences. The optimal $T^*$ minimizes the sum of aggregation error (increasing in $T$) and impossibility proximity (increasing as $T \to 0$).
\end{proof}

\subsection{$\rho$-Dependent Democratic Robustness}

\begin{proposition}[Robustness of Political Institutions]\label{prop:democracy}
The critical temperature $T^*_{\text{democracy}}$ above which democratic aggregation fails depends on $\rho$:
\begin{equation}
    T^*_{\text{democracy}}(\rho) \text{ is increasing in } \rho
\end{equation}
High-$\rho$ (majoritarian) systems tolerate more informational noise than low-$\rho$ (consensus) systems.
\end{proposition}

\begin{proof}[Proof sketch]
For $\rho$ near 1 (utilitarian/majoritarian), the CES aggregate approximates the mean of utilities. The mean is estimated consistently by majority voting, and individual noise washes out by the law of large numbers. For $\rho \ll 0$ (Rawlsian/consensus), the CES aggregate is sensitive to the minimum utility. Estimating the minimum requires precise information about the tails of the distribution, which is highly sensitive to noise. Therefore, low-$\rho$ aggregation fails at lower $T$.
\end{proof}

\subsection{Empirical Implications}

\Cref{prop:democracy} predicts which political systems are robust to increasing informational noise (polarization, misinformation, declining institutional trust):

\begin{center}
\begin{tabular}{llll}
\toprule
\textbf{System} & \textbf{Effective $\rho$} & \textbf{$T$ tolerance} & \textbf{Current status} \\
\midrule
Simple majority / referendum & High ($\approx 1$) & High & Functioning \\
Proportional representation & Moderate & Moderate & Under stress \\
Supermajority / filibuster & Low & Low & Gridlocked \\
Unanimity requirements & Very low ($\to -\infty$) & Very low & Paralyzed \\
\bottomrule
\end{tabular}
\end{center}

The prediction matches observed institutional performance: the US Senate filibuster (low $\rho$) is gridlocked; EU unanimity requirements (very low $\rho$) produce paralysis on major issues; majoritarian systems (UK Parliament, Swiss referenda, high $\rho$) continue to produce outcomes even under elevated informational noise.

\subsection{Connection to the Condorcet Jury Theorem}

The Condorcet jury theorem \citep{condorcet1785} states that majority voting converges to the correct outcome as $J \to \infty$, provided each voter has probability $p > 1/2$ of being correct. In the entropy framework: each voter provides $I = 1 - H(p)$ bits of information. The condition $p > 1/2$ is equivalent to $I > 0$ (positive information per voter).

The CES extension: voters with \emph{heterogeneous} expertise across issues are more valuable than homogeneous voters when $\rho < 1$. The CES superadditivity of diverse voter knowledge provides an epistemic bonus---the electorate collectively knows more than any subgroup. This is the epistemic argument for democracy, derived from the CES triple role.

%=============================================================================
\section{Extensions}\label{sec:extensions}
%=============================================================================

The three derivations above follow an identical pattern: information friction degrades a CES aggregate, with severity controlled by $\rho$ and temperature $T$. This section sketches how the same pattern extends to three additional areas, with detailed treatments deferred to companion papers.

\subsection{Search and Matching}\label{sec:extensions_search}

The Diamond-Mortensen-Pissarides matching function $M = A \cdot U^\alpha V^{1-\alpha}$ \citep{diamond1982,mortensen1982,pissarides1985} is CES at the Cobb-Douglas limit ($\rho \to 0$). Search is entropy reduction: each meeting between a worker and firm reduces $H(\text{match quality})$ by $\Delta H$. Unemployment duration equals the time to reduce entropy below the matching threshold.

The $\rho$-dependent prediction: labor markets with lower $\rho$ (more specialized skills, higher complementarity between worker and position) sustain longer search and higher wages. The Beveridge curve outward shift observed since 2000 corresponds to declining $\rho$ as the economy becomes more specialized.

\subsection{Contract Theory}\label{sec:extensions_contracts}

Hart-Moore incomplete contracts \citep{hart1990} arise when some variables have $H = \infty$ (non-verifiable). The GHM property rights result---ownership to the party whose non-contractible investment has higher CES marginal product---follows from maximizing $\Phi$ over the contractible dimensions.

Williamson's asset specificity \citep{williamson1985} is identified as low $\rho$: an asset is ``specific'' to a relationship precisely because it is complementary (low $\rho$) to the partner's inputs. This unifies Hart-Moore and Williamson through $\rho$: asset specificity = CES complementarity = hold-up severity. The vertical integration decision is a $\rho$ decision.

\subsection{Behavioral Economics}\label{sec:extensions_behavioral}

Behavioral economics \citep{kahneman1979,thaler2008} catalogs systematic deviations from rational choice: loss aversion, framing effects, present bias, anchoring, status quo bias, mental accounting. In the free energy framework, these are not separate ``biases'' but the complete characterization of economic behavior at $T > 0$.

The only additional parameter needed is \emph{asymmetric temperature}: $T_{\text{loss}} < T_{\text{gain}}$. Losses are processed more precisely (lower temperature) than gains. The ratio $T_{\text{gain}}/T_{\text{loss}} \approx \lambda \approx 2.25$ is Kahneman-Tversky's loss aversion coefficient, reinterpreted as a processing temperature ratio with plausible evolutionary origins.

Each behavioral phenomenon maps to a specific $T > 0$ effect: probability weighting is incomplete processing of extreme probabilities; anchoring is insufficient entropy reduction from the prior; status quo bias is the entropy cost advantage of the default; nudge effectiveness is proportional to $T$; and hyperbolic discounting is exponential discounting plus an entropy penalty that grows sub-linearly with temporal distance.

%=============================================================================
\section{The Architecture}\label{sec:architecture}
%=============================================================================

\subsection{What Is Unified}

\Cref{tab:unified} summarizes the unification. Six areas of economic theory, associated with eight Nobel Prizes, emerge as specific instances of the free energy framework \eqref{eq:economic_free_energy}.

\begin{table}[htbp]
\centering
\small
\begin{tabular}{p{2.8cm}p{2.5cm}p{4.5cm}p{4.5cm}}
\toprule
\textbf{Area} & \textbf{Nobel} & \textbf{Key result derived} & \textbf{New $\rho$-dependent prediction} \\
\midrule
Information economics & Akerlof 2001 & Unraveling = CES degrading under entropy & $T^* \propto K$: complements resist adverse selection \\[6pt]
Search / matching & DMP 2010 & Matching function = CES; search = entropy reduction & $\rho$ explains duration heterogeneity, Beveridge shift \\[6pt]
Mechanism design & HMM 2007 & Virtual valuation = free energy gradient & PoIC$(\rho)$; mechanism format from $\rho$ \\[6pt]
Contract theory & Hart-Holmstr\"{o}m 2016; Williamson 2009 & Hold-up, integration from $\rho$; asset specificity = low $\rho$ & Two Nobels unified through $\rho$ \\[6pt]
Social choice & Arrow 1972 & Impossibility = $T{=}0$ phase transition & Democratic robustness depends on $\rho$ \\[6pt]
Behavioral economics & Kahneman 2002; Thaler 2017 & Behavioral catalog = $T{>}0$ phenomena & $T_{\text{gain}}/T_{\text{loss}}$ unifies loss aversion family \\
\bottomrule
\end{tabular}
\caption{Unification of six areas of economic theory through the free energy framework $\mathcal{F} = \Phi_{\text{CES}}(\rho) - T \cdot H$. Each area emerges as information friction degrading a CES aggregate, with severity controlled by $\rho$.}
\label{tab:unified}
\end{table}

\subsection{What Determines What}

The two parameters have clean domains:

\begin{itemize}
    \item $\rho$ (CES curvature) determines \textbf{structure}: whether markets are competitive or monopolistic, whether networks have strong or weak effects, whether assets are specific or generic, whether mechanisms require complex screening or simple auctions, whether political systems tolerate noise or gridlock.

    \item $T$ (information temperature) determines \textbf{friction}: how precisely agents optimize, how quickly markets clear, how much information rent mechanisms must concede, how well democratic aggregation approximates the social optimum, how large behavioral deviations are.
\end{itemize}

The interaction $\rho \times T$ determines \textbf{institutional viability}: whether a given institution (market, contract, mechanism, political system) functions or fails. The critical temperature $T^* \propto K(\rho)$ is the institutional failure boundary.

\subsection{What Remains Separate}

The framework does not claim to derive all of economic theory from two parameters. It claims that the \emph{aggregation-information boundary}---the interface between how inputs combine and what agents know---is governed by $(\rho, T)$.

Areas that may require additional structure include:
\begin{itemize}
    \item Specific institutional forms (why firms rather than markets, why democracies rather than autocracies);
    \item Historical contingency and path dependence;
    \item The determination of $\rho$ itself (what makes some inputs complementary and others substitutable);
    \item The biological/neurological basis of $T$ and the $T_{\text{gain}}/T_{\text{loss}}$ asymmetry.
\end{itemize}

These are legitimate extensions, not contradictions. The framework provides the scaffolding; the specific content of each domain provides the architecture.

%=============================================================================
\section{Discussion}\label{sec:discussion}
%=============================================================================

\subsection{Why Wasn't This Seen Before?}

The components of this framework are not new. CES aggregates have been used since \citet{arrow1961}. Shannon entropy has been applied to economics since \citet{theil1967}. Free energy principles are standard in physics. Each component is textbook material.

The unity was obscured by the structure of the economics profession. Trade economists use CES for Armington elasticities. Macro economists use CES for production functions. Information economists use entropy for adverse selection. Mechanism designers use entropy for incentive constraints. Behavioral economists use noise models for bounded rationality. Each group uses its piece of the framework without recognizing it as a piece.

The CES quadruple role theorem \citep{smirl2026ces} was the key that unlocked the unity. Once one recognizes that $\rho$ simultaneously controls superadditivity, correlation robustness, strategic independence, and network scaling, the question ``what else does $\rho$ control?'' leads directly to the information-theoretic extension.

\subsection{Testability}

Every derivation in this paper produces predictions that the original theory does not:
\begin{itemize}
    \item Akerlof + $\rho$: market robustness to adverse selection varies with complementarity.
    \item Myerson + $\rho$: price of incentive compatibility and optimal mechanism format depend on complementarity.
    \item Arrow + $\rho$: democratic institutional robustness depends on the social welfare parameter.
    \item DMP + $\rho$: unemployment duration heterogeneity and Beveridge curve shifts explained by skill complementarity.
    \item Hart-Moore + Williamson + $\rho$: asset specificity, hold-up severity, and vertical integration decisions unified through complementarity.
    \item Kahneman-Tversky + $T_{\text{gain}}/T_{\text{loss}}$: loss aversion coefficient is a temperature ratio.
\end{itemize}

Each prediction is cross-sectionally testable: estimate $\rho$ for each market/institution and check whether the framework's predictions hold across markets with different $\rho$ values.

\subsection{Implications for Economic Methodology}

If the framework is correct, several methodological implications follow:
\begin{enumerate}
    \item The division of economics into ``micro'' and ``macro,'' or ``rational'' and ``behavioral,'' reflects the two terms of the free energy, not a fundamental disciplinary boundary.

    \item The assumption of ``perfect rationality'' is not wrong---it is the $T = 0$ limit of a more general theory, valid when information costs are negligible relative to stakes.

    \item The ``biases'' documented by behavioral economics are not failures of rationality but the thermodynamically inevitable consequences of finite information processing capacity.

    \item Arrow's impossibility theorem does not demonstrate the impossibility of democracy---it demonstrates that deterministic preference aggregation is a degenerate limit of a well-behaved probabilistic aggregation.
\end{enumerate}

%=============================================================================
\section{Conclusion}\label{sec:conclusion}
%=============================================================================

This paper has proposed that economic theory is generated by two canonical functions---the CES aggregate and Shannon entropy---connected through a free energy principle. The framework is parameterized by $\rho$ (controlling aggregation structure) and $T$ (controlling information friction), with the interaction determining institutional viability.

Three detailed derivations and three sketched extensions demonstrate that six major areas of economic theory, spanning eight Nobel Prizes, emerge as specific instances of this framework. Each derivation produces new $\rho$-dependent predictions that the original theories cannot generate.

The framework is a conjecture, not a completed theory. Rigorous formalization of each derivation, empirical testing of the cross-sectional $\rho$-dependent predictions, and investigation of the framework's boundaries are needed. But the structural correspondence across six independent areas of economic theory is difficult to attribute to coincidence. If even a subset of the derivations survives formal scrutiny, the implication is that the economics profession has spent decades independently discovering specific consequences of a two-parameter generating function---in separate subfields, with separate terminology, awarding separate prizes---without recognizing the unity.

The equation is:
\begin{equation*}
    \mathcal{F} = \Phi_{\text{CES}}(\rho) - T \cdot H
\end{equation*}

Two parameters. One equation. The rest is application.

\newpage
%=============================================================================
% References
%=============================================================================
\bibliographystyle{aer}

\begin{thebibliography}{99}

\bibitem[Akerlof(1970)]{akerlof1970}
Akerlof, George A. 1970. ``The Market for `Lemons': Quality Uncertainty and the Market Mechanism.'' \textit{Quarterly Journal of Economics} 84(3): 488--500.

\bibitem[Armington(1969)]{armington1969}
Armington, Paul S. 1969. ``A Theory of Demand for Products Distinguished by Place of Production.'' \textit{IMF Staff Papers} 16(1): 159--178.

\bibitem[Arrow(1951)]{arrow1951}
Arrow, Kenneth J. 1951. \textit{Social Choice and Individual Values}. New York: Wiley.

\bibitem[Arrow et~al.(1961)]{arrow1961}
Arrow, Kenneth J., Hollis B. Chenery, Bagicha S. Minhas, and Robert M. Solow. 1961. ``Capital-Labor Substitution and Economic Efficiency.'' \textit{Review of Economics and Statistics} 43(3): 225--250.

\bibitem[Atkinson(1970)]{atkinson1970}
Atkinson, Anthony B. 1970. ``On the Measurement of Inequality.'' \textit{Journal of Economic Theory} 2(3): 244--263.

\bibitem[Bergemann and Morris(2019)]{bergemann2019}
Bergemann, Dirk, and Stephen Morris. 2019. ``Information Design: A Unified Perspective.'' \textit{Journal of Economic Literature} 57(1): 44--95.

\bibitem[Condorcet(1785)]{condorcet1785}
Condorcet, Marquis de. 1785. \textit{Essai sur l'application de l'analyse \`{a} la probabilit\'{e} des d\'{e}cisions rendues \`{a} la pluralit\'{e} des voix}. Paris: Imprimerie Royale.

\bibitem[Diamond(1982)]{diamond1982}
Diamond, Peter A. 1982. ``Aggregate Demand Management in Search Equilibrium.'' \textit{Journal of Political Economy} 90(5): 881--894.

\bibitem[Dixit and Stiglitz(1977)]{dixit1977}
Dixit, Avinash K., and Joseph E. Stiglitz. 1977. ``Monopolistic Competition and Optimum Product Diversity.'' \textit{American Economic Review} 67(3): 297--308.

\bibitem[Smirl(2026a)]{smirl2026ces}
Smirl, Jon. 2026a. ``The CES Triple Role: Superadditivity, Correlation Robustness, and Strategic Independence as Three Views of Isoquant Curvature.'' SSRN Working Paper 6263482. \url{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6263482}.

\bibitem[Hart and Moore(1990)]{hart1990}
Hart, Oliver, and John Moore. 1990. ``Property Rights and the Nature of the Firm.'' \textit{Journal of Political Economy} 98(6): 1119--1158.

\bibitem[Kahneman and Tversky(1979)]{kahneman1979}
Kahneman, Daniel, and Amos Tversky. 1979. ``Prospect Theory: An Analysis of Decision under Risk.'' \textit{Econometrica} 47(2): 263--291.

\bibitem[Khinchin(1957)]{khinchin1957}
Khinchin, Aleksandr I. 1957. \textit{Mathematical Foundations of Information Theory}. New York: Dover.

\bibitem[Krugman(1991)]{krugman1991}
Krugman, Paul. 1991. ``Increasing Returns and Economic Geography.'' \textit{Journal of Political Economy} 99(3): 483--499.

\bibitem[McKelvey and Palfrey(1995)]{mckelvey1995}
McKelvey, Richard D., and Thomas R. Palfrey. 1995. ``Quantal Response Equilibria for Normal Form Games.'' \textit{Games and Economic Behavior} 10(1): 6--38.

\bibitem[Mortensen(1982)]{mortensen1982}
Mortensen, Dale T. 1982. ``The Matching Process as a Noncooperative Bargaining Game.'' In \textit{The Economics of Information and Uncertainty}, ed. John J. McCall, 233--258.

\bibitem[Myerson(1981)]{myerson1981}
Myerson, Roger B. 1981. ``Optimal Auction Design.'' \textit{Mathematics of Operations Research} 6(1): 58--73.

\bibitem[Pissarides(1985)]{pissarides1985}
Pissarides, Christopher A. 1985. ``Short-Run Equilibrium Dynamics of Unemployment, Vacancies, and Real Wages.'' \textit{American Economic Review} 75(4): 676--690.

\bibitem[Romer(1990)]{romer1990}
Romer, Paul M. 1990. ``Endogenous Technological Change.'' \textit{Journal of Political Economy} 98(5): S71--S102.

\bibitem[Shannon(1948)]{shannon1948}
Shannon, Claude E. 1948. ``A Mathematical Theory of Communication.'' \textit{Bell System Technical Journal} 27(3): 379--423.

\bibitem[Sims(2003)]{sims2003}
Sims, Christopher A. 2003. ``Implications of Rational Inattention.'' \textit{Journal of Monetary Economics} 50(3): 665--690.

\bibitem[Solow(1956)]{solow1956}
Solow, Robert M. 1956. ``A Contribution to the Theory of Economic Growth.'' \textit{Quarterly Journal of Economics} 70(1): 65--94.

\bibitem[Thaler and Sunstein(2008)]{thaler2008}
Thaler, Richard H., and Cass R. Sunstein. 2008. \textit{Nudge: Improving Decisions About Health, Wealth, and Happiness}. New Haven: Yale University Press.

\bibitem[Theil(1967)]{theil1967}
Theil, Henri. 1967. \textit{Economics and Information Theory}. Amsterdam: North-Holland.

\bibitem[Williamson(1985)]{williamson1985}
Williamson, Oliver E. 1985. \textit{The Economic Institutions of Capitalism}. New York: Free Press.

\bibitem[Yakovenko and Rosser(2009)]{yakovenko2009}
Yakovenko, Victor M., and J. Barkley Rosser Jr. 2009. ``Colloquium: Statistical Mechanics of Money, Wealth, and Income.'' \textit{Reviews of Modern Physics} 81(4): 1703--1725.

\end{thebibliography}

\end{document}
